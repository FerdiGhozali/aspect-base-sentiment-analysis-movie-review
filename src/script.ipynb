{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_adj(sentence, keyword, skip_before_keyword=False, skip_after_keyword=False, prev_bag_of_word=1, after_bag_of_word=5) :    \n",
    "    st = StanfordPOSTagger('./english-bidirectional-distsim.tagger', './stanford-postagger-3.9.2.jar')\n",
    "    \n",
    "    punctuation = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'] # remove it if you need punctuation \n",
    "    \n",
    "    word_tokens = word_tokenize(sentence) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in punctuation] \n",
    "    filtered_sentence = [] \n",
    "  \n",
    "    for w in word_tokens: \n",
    "        if w not in punctuation:\n",
    "            filtered_sentence.append(w)\n",
    "            \n",
    "    list_word_tag = st.tag([(\" \").join(filtered_sentence)])\n",
    "    found_keyword = not skip_before_keyword\n",
    "    list_sentiment_word = []\n",
    "    found_adjective = 0\n",
    "    keyword_idx = -1\n",
    "    for idx in range (len(list_word_tag)) :\n",
    "        if (list_word_tag[idx][0] == keyword) :\n",
    "            keyword_idx = idx\n",
    "            break\n",
    "    \n",
    "    if (skip_before_keyword) :\n",
    "        prev_bag_of_word = 0\n",
    "    \n",
    "    if (skip_after_keyword) :\n",
    "        after_bag_of_word = 0\n",
    "        \n",
    "    for idx in range (len(list_word_tag)) :\n",
    "        if (idx > keyword_idx + after_bag_of_word) :\n",
    "                break\n",
    "                \n",
    "        if ((idx >= keyword_idx - prev_bag_of_word) and list_word_tag[idx][1] == 'JJ') :\n",
    "            found_adjective += 1\n",
    "            sentiment_word = list_word_tag[idx][0]\n",
    "            for adverb_idx in range (idx-1, -1, -1) :\n",
    "                if (list_word_tag[adverb_idx][1] == 'RB') :\n",
    "                    sentiment_word = list_word_tag[adverb_idx][0] + \" \" + sentiment_word\n",
    "                else :\n",
    "                    break\n",
    "            list_sentiment_word.append(sentiment_word)\n",
    "            \n",
    "    return (list_sentiment_word, found_adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document, skip_before_keyword=False, skip_after_keyword=False, prev_bag_of_word=1, after_bag_of_word=5) :\n",
    "    act = ['acting','role playing','act',' actress','actor','role','portray','character','villain','performance', 'play', 'perform', 'doing']\n",
    "    plot = ['plot','story','storyline','tale','romance','dialog','script','storyteller',' ending','storytelling','revenge','betrayal','writing']\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    act_sentence = []\n",
    "    plot_sentence = []\n",
    "    act_score = 0\n",
    "    plot_score = 0\n",
    "    tokenizer = tokenize.PunktSentenceTokenizer()\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    list_sentence = tokenizer.sentences_from_text(document)\n",
    "    for sentence in list_sentence :\n",
    "        is_sentence_act = False\n",
    "        is_sentence_plot = False\n",
    "        list_word = tokenize.word_tokenize(sentence)\n",
    "        for word in list_word :\n",
    "            if (ps.stem(word.lower()) in act or word.lower() in act):\n",
    "                list_adj_sentence, adj_found = search_adj(sentence, word, prev_bag_of_word=prev_bag_of_word, after_bag_of_word=after_bag_of_word)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    display(adj_word)\n",
    "                    act_sentence.append(adj_word)\n",
    "                    act_score += sid.polarity_scores(adj_word)['pos'] - sid.polarity_scores(adj_word)['neg']\n",
    "            if (ps.stem(word.lower()) in plot or word.lower() in plot):\n",
    "                list_adj_sentence, adj_found = search_adj(sentence, word, prev_bag_of_word=prev_bag_of_word, after_bag_of_word=after_bag_of_word)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    display(adj_word)\n",
    "                    plot_sentence.append(adj_word)\n",
    "                    plot_score +=  sid.polarity_scores(adj_word)['pos'] - sid.polarity_scores(adj_word)['neg']\n",
    "#     return ([act_sentence,plot_sentence])\n",
    "    return ([act_score,plot_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_sentence(list_of_word) :\n",
    "    return((\" \").join(list_of_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTOH PENGGUNAAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "data = pd.read_excel(\"../input/datasetnlp_nographic_no_neutral.xlsx\")\n",
    "data = data\n",
    "data.drop(columns=['title'], inplace=True)\n",
    "for column_name in ['acting', 'plot'] :\n",
    "    data.loc[data[column_name] == 'positive', column_name] = 1\n",
    "    data.loc[data[column_name] == 'negative', column_name] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "tokenizer = tokenize.PunktSentenceTokenizer()\n",
    "data.text = data.text.apply(lambda x: preprocessing(x, prev_bag_of_word=1, after_bag_of_word=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act = pd.DataFrame([])\n",
    "# data_act['text'] = [i[0] for i in data.iloc[:,0].tolist()]\n",
    "# data_act.text = data_act.text.apply(lambda x: list_to_sentence(x))\n",
    "data_act['sentiment_score'] = [i[0] for i in data.iloc[:,0].tolist()]\n",
    "data_act['label'] = data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = pd.DataFrame([])\n",
    "# data_plot['text'] = [i[1] for i in data.iloc[:,0].tolist()]\n",
    "# data_plot.text = data_plot.text.apply(lambda x: list_to_sentence(x))\n",
    "data_plot['sentiment_score'] = [i[1] for i in data.iloc[:,0].tolist()]\n",
    "data_plot['label'] = data.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer()\n",
    "# X_act_counts = count_vect.fit_transform(data_act.text)\n",
    "# X_act_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_plot_counts = count_vect.fit_transform(data_plot.text)\n",
    "# X_plot_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_act_tfidf = tfidf_transformer.fit_transform(X_act_counts)\n",
    "# X_act_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_plot_tfidf = tfidf_transformer.fit_transform(X_plot_counts)\n",
    "# X_plot_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_act = X_act_tfidf\n",
    "# feature_plot = X_plot_tfidf\n",
    "feature_act = pd.DataFrame(data_act['sentiment_score'])\n",
    "feature_plot = pd.DataFrame(data_plot['sentiment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # learning\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# clf1 = MultinomialNB().fit(feature_act, data_act.label.tolist())\n",
    "# clf2 = MultinomialNB().fit(feature_plot, data_plot.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naiv1 = clf1.predict(X_act_tfidf)\n",
    "# naiv2 = clf2.predict(X_plot_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_svm1 = naiv1.predict(pd.DataFrame(feature_act))\n",
    "# pred_svm2 = naiv2.predict(pd.DataFrame(feature_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm1 = svm.SVC().fit(feature_act, data_act.label.tolist())\n",
    "svm2 = svm.SVC().fit(feature_plot, data_plot.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm1 = svm1.predict(pd.DataFrame(feature_act))\n",
    "pred_svm2 = svm2.predict(pd.DataFrame(feature_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(pred_svm1, data_act.label.tolist()),\n",
    "        f1_score(pred_svm2, data_plot.label.tolist())\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1 = RandomForestClassifier(n_estimators=10)\n",
    "rf1.fit(feature_act, data_act.label.tolist())\n",
    "rf2 = RandomForestClassifier(n_estimators=10)\n",
    "rf2.fit(feature_plot, data_plot.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "pred_rf1 = rf1.predict(feature_act)\n",
    "pred_rf2 = rf2.predict(feature_plot)\n",
    "cv10_pred_rf1 = cross_val_predict(rf1, feature_act, data_act.label.tolist(), cv=10)\n",
    "cv10_pred_rf2 = cross_val_predict(rf2, feature_plot, data_plot.label.tolist(), cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.score(feature_act, data_act.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.score(feature_plot, data_plot.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(cv10_pred_rf1, data_act.label.tolist()),\n",
    "        f1_score(cv10_pred_rf2, data_plot.label.tolist())\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb1 = XGBClassifier(max_depth=5,objective='binary:logistic',learning_rate=0.001,min_child_weight=1,scale_pos_weight=1)\n",
    "xgb2 = XGBClassifier(max_depth=5,objective='binary:logistic',learning_rate=0.001,min_child_weight=1,scale_pos_weight=1)\n",
    "\n",
    "predict_xgb_1 = cross_val_predict(xgb1, feature_act, data_act.label.tolist(), cv=10)\n",
    "predict_xgb_2 = cross_val_predict(xgb2, feature_plot, data_plot.label.tolist(), cv=10)\n",
    "\n",
    "cv10_predict_xgb_1 = xgb1.fit(feature_act, data_act.label.tolist()).predict(feature_act)\n",
    "cv10_predict_xgb_2 = xgb2.fit(feature_plot, data_plot.label.tolist()).predict(feature_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7924528301886793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(predict_xgb_1, data_act.label.tolist()),\n",
    "        f1_score(predict_xgb_2, data_plot.label.tolist()),\n",
    "        f1_score(cv10_predict_xgb_1, data_act.label.tolist()),\n",
    "        f1_score(cv10_predict_xgb_2, data_plot.label.tolist())\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acting => positive\n",
      "plot => positive\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(teks) :\n",
    "    sentiment_score = preprocessing(teks)\n",
    "    sentiment_score_act = pd.DataFrame([sentiment_score[0]], columns=[\"sentiment_score\"])\n",
    "    sentiment_score_plot = pd.DataFrame([sentiment_score[1]], columns=[\"sentiment_score\"])\n",
    "    act_sentiment = xgb1.predict(sentiment_score_act)\n",
    "    plot_sentiment = xgb2.predict(sentiment_score_plot)\n",
    "    \n",
    "    return(act_sentiment[0], plot_sentiment[0])\n",
    "    \n",
    "    \n",
    "act_sentiment, plot_sentiment = predict_sentiment('bad act')\n",
    "display(act_sentiment, plot_sentiment)\n",
    "if (act_sentiment == 1) :\n",
    "    print(\"acting => positive\")\n",
    "else :\n",
    "    print(\"acting => negative\")\n",
    "if (plot_sentiment == 1) :\n",
    "    print(\"plot => positive\")\n",
    "else :\n",
    "    print(\"plot => negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "new_dataset = smote.fit_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521.3793420791626\n"
     ]
    }
   ],
   "source": [
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "a = list(swn.senti_synsets('not'))\n",
    "pos = 0\n",
    "neg = 0\n",
    "pos=pos+a[0].pos_score()\n",
    "neg=neg+a[0].neg_score()\n",
    "display(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
