{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_adj(sentence, keyword, skip_before_keyword=False, skip_after_keyword=False, prev_bag_of_word=5, after_bag_of_word=5) :    \n",
    "    st = StanfordPOSTagger('./english-bidirectional-distsim.tagger', './stanford-postagger-3.9.2.jar')\n",
    "    \n",
    "#     stopword elemination\n",
    "#     stop_words = set(stopwords.words('english')) \n",
    "#     stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) # remove it if you need punctuation \n",
    "    punctuation = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'] # remove it if you need punctuation \n",
    "    \n",
    "    word_tokens = word_tokenize(sentence) \n",
    "#     filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [w for w in word_tokens if not w in punctuation] \n",
    "    filtered_sentence = [] \n",
    "  \n",
    "    for w in word_tokens: \n",
    "#         if w not in stop_words:\n",
    "        if w not in punctuation:\n",
    "            filtered_sentence.append(w)\n",
    "            \n",
    "    list_word_tag = st.tag([(\" \").join(filtered_sentence)])\n",
    "    found_keyword = not skip_before_keyword\n",
    "    list_sentiment_word = []\n",
    "    found_adjective = 0\n",
    "    keyword_idx = -1\n",
    "    for idx in range (len(list_word_tag)) :\n",
    "        if (list_word_tag[idx][0] == keyword) :\n",
    "            keyword_idx = idx\n",
    "            break\n",
    "    \n",
    "    if (skip_before_keyword) :\n",
    "        prev_bag_of_word = 0\n",
    "    \n",
    "    if (skip_after_keyword) :\n",
    "        after_bag_of_word = 0\n",
    "        \n",
    "    for idx in range (len(list_word_tag)) :\n",
    "        if (idx > keyword_idx + after_bag_of_word) :\n",
    "                break\n",
    "                \n",
    "        if ((idx >= keyword_idx - prev_bag_of_word) and list_word_tag[idx][1] == 'JJ') :\n",
    "            found_adjective += 1\n",
    "            sentiment_word = list_word_tag[idx][0]\n",
    "            for adverb_idx in range (idx-1, -1, -1) :\n",
    "                if (list_word_tag[adverb_idx][1] == 'RB') :\n",
    "                    sentiment_word = list_word_tag[adverb_idx][0] + \" \" + sentiment_word\n",
    "                else :\n",
    "                    break\n",
    "            list_sentiment_word.append(sentiment_word)\n",
    "            \n",
    "    return (list_sentiment_word, found_adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document, skip_before_keyword=False, skip_after_keyword=False, prev_bag_of_word=5, after_bag_of_word=5) :\n",
    "    act = ['acting','role playing','act',' actress','actor','role','portray','character','villain','performance', 'play', 'perform', 'doing']\n",
    "    plot = ['plot','story','storyline','tale','romance','dialog','script','storyteller',' ending','storytelling','revenge','betrayal','writing']\n",
    "    graphic = ['movie',' film',' picture',' moving picture','',' motion picture',' show',' picture show',' pic',' flick',' romantic comedy', 'graphic', 'effect', 'cinematography', 'cinematographi']\n",
    "    \n",
    "    act_sentence = []\n",
    "    plot_sentence = []\n",
    "    graphic_sentence = []\n",
    "    \n",
    "    tokenizer = tokenize.PunktSentenceTokenizer()\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    list_sentence = tokenizer.sentences_from_text(document)\n",
    "    for sentence in list_sentence :\n",
    "        is_sentence_act = False\n",
    "        is_sentence_plot = False\n",
    "        is_sentence_graphic = False\n",
    "        list_word = tokenize.word_tokenize(sentence)\n",
    "        for word in list_word :\n",
    "            if (ps.stem(word.lower()) in act):\n",
    "                list_adj_sentence, adj_found = search_adj(sentence, word, prev_bag_of_word=prev_bag_of_word, after_bag_of_word=after_bag_of_word)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    act_sentence.append(adj_word)\n",
    "            if (ps.stem(word.lower()) in plot):\n",
    "                list_adj_sentence, adj_found = search_adj(sentence, word, prev_bag_of_word=prev_bag_of_word, after_bag_of_word=after_bag_of_word)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    plot_sentence.append(adj_word)\n",
    "            if (ps.stem(word.lower()) in graphic):\n",
    "                list_adj_sentence, adj_found = search_adj(sentence, word, prev_bag_of_word=prev_bag_of_word, after_bag_of_word=after_bag_of_word)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    graphic_sentence.append(adj_word)\n",
    "    return ([act_sentence,plot_sentence, graphic_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_sentence(list_of_word) :\n",
    "    return((\" \").join(list_of_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTOH PENGGUNAAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#your code here    \n",
    "\n",
    "# input data\n",
    "data = pd.read_excel(\"../input/datasetnlp.xlsx\")\n",
    "data = data\n",
    "data.drop(columns=['title'], inplace=True)\n",
    "for column_name in ['acting', 'plot', 'graphic'] :\n",
    "    data.loc[data[column_name] == 'positive', column_name] = 1\n",
    "    data.loc[data[column_name] == 'neutral', column_name] = 0\n",
    "    data.loc[data[column_name] == 'negative', column_name] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "tokenizer = tokenize.PunktSentenceTokenizer()\n",
    "data.text = data.text.apply(lambda x: preprocessing(x, prev_bag_of_word=1, after_bag_of_word=10))\n",
    "\n",
    "data_act = pd.DataFrame([])\n",
    "data_act['text'] = [i[0] for i in data.iloc[:,0].tolist()]\n",
    "data_act.text = data_act.text.apply(lambda x: list_to_sentence(x))\n",
    "data_act['label'] = data.iloc[:,1]\n",
    "\n",
    "data_plot = pd.DataFrame([])\n",
    "data_plot['text'] = [i[1] for i in data.iloc[:,0].tolist()]\n",
    "data_plot.text = data_plot.text.apply(lambda x: list_to_sentence(x))\n",
    "data_plot['label'] = data.iloc[:,2]\n",
    "\n",
    "data_graphic = pd.DataFrame([])\n",
    "data_graphic['text'] = [i[2] for i in data.iloc[:,0].tolist()]\n",
    "data_graphic.text = data_graphic.text.apply(lambda x: list_to_sentence(x))\n",
    "data_graphic['label'] = data.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_act_counts = count_vect.fit_transform(data_act.text)\n",
    "X_act_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_plot_counts = count_vect.fit_transform(data_plot.text)\n",
    "X_plot_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_graphic_counts = count_vect.fit_transform(data_graphic.text)\n",
    "X_graphic_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_act_tfidf = tfidf_transformer.fit_transform(X_act_counts)\n",
    "X_act_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 31)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_plot_tfidf = tfidf_transformer.fit_transform(X_plot_counts)\n",
    "X_plot_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 31)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_graphic_tfidf = tfidf_transformer.fit_transform(X_graphic_counts)\n",
    "X_graphic_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf1 = MultinomialNB().fit(X_act_tfidf, data_act.label.tolist())\n",
    "clf2 = MultinomialNB().fit(X_plot_tfidf, data_plot.label.tolist())\n",
    "clf3 = MultinomialNB().fit(X_graphic_tfidf, data_graphic.label.tolist())\n",
    "\n",
    "pred1 = clf1.predict(X_act_tfidf)\n",
    "pred2 = clf2.predict(X_plot_tfidf)\n",
    "pred3 = clf3.predict(X_graphic_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0719007274919957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.07801825897946923"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408.0002744197845\n"
     ]
    }
   ],
   "source": [
    "# scoring\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "display(adjusted_mutual_info_score(pred1, data_act.label))\n",
    "display(adjusted_mutual_info_score(pred2, data_plot.label))\n",
    "display(adjusted_mutual_info_score(pred3, data_graphic.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm1 = svm.SVC().fit(X_act_tfidf, data_act.label.tolist())\n",
    "svm2 = svm.SVC().fit(X_plot_tfidf, data_plot.label.tolist())\n",
    "svm3 = svm.SVC().fit(X_graphic_tfidf, data_graphic.label.tolist())\n",
    "\n",
    "pred_svm1 = svm1.predict(X_act_tfidf)\n",
    "pred_svm2 = svm2.predict(X_plot_tfidf)\n",
    "pred_svm3 = svm3.predict(X_graphic_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.556002065456463e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.9277665585433085e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "display(adjusted_mutual_info_score(pred_svm1, data_act.label))\n",
    "display(adjusted_mutual_info_score(pred_svm2, data_plot.label))\n",
    "display(adjusted_mutual_info_score(pred_svm3, data_graphic.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=10).fit(X_act_tfidf, data_act.label.tolist())\n",
    "rf2 = RandomForestClassifier(n_estimators=10).fit(X_plot_tfidf, data_plot.label.tolist())\n",
    "rf3 = RandomForestClassifier(n_estimators=10).fit(X_graphic_tfidf, data_graphic.label.tolist())\n",
    "\n",
    "pred_rf1 = rf1.predict(X_act_tfidf)\n",
    "pred_rf2 = rf2.predict(X_plot_tfidf)\n",
    "pred_rf3 = rf3.predict(X_graphic_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41563280042654266"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2879504908233778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3057686994829927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "display(adjusted_mutual_info_score(pred_rf1, data_act.label))\n",
    "display(adjusted_mutual_info_score(pred_rf2, data_plot.label))\n",
    "display(adjusted_mutual_info_score(pred_rf3, data_graphic.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
