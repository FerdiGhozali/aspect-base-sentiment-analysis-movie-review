{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "def search_adj(sentence, keyword, skip_before_keyword, skip_after_keyword, prev_bag_of_word=5, after_bag_of_word=5) :    \n",
    "    st = StanfordPOSTagger('./english-bidirectional-distsim.tagger', './stanford-postagger-3.9.2.jar')\n",
    "    list_word_tag = st.tag([sentence])\n",
    "    found_keyword = not skip_before_keyword\n",
    "    list_sentiment_word = []\n",
    "    found_adjective = 0\n",
    "    keyword_idx = -1\n",
    "    for idx in range (len(list_word_tag)) :\n",
    "        if (list_word_tag[idx][0] == keyword) :\n",
    "            keyword_idx = idx\n",
    "            break\n",
    "    \n",
    "    if (skip_before_keyword) :\n",
    "        prev_bag_of_word = 0\n",
    "    \n",
    "    if (skip_after_keyword) :\n",
    "        after_bag_of_word = 0\n",
    "        \n",
    "    for idx in range (len(list_word_tag)) :\n",
    "        if (idx >= keyword_idx + bag_of_word) :\n",
    "                break\n",
    "                \n",
    "        if ((idx >= keyword_idx - bag_of_word) && list_word_tag[idx][1] == 'JJ') :\n",
    "            found_adjective += 1\n",
    "            sentiment_word = list_word_tag[idx][0]\n",
    "            for adverb_idx in range (idx-1, -1, -1) :\n",
    "                if (list_word_tag[adverb_idx][1] == 'RB') :\n",
    "                    sentiment_word = list_word_tag[adverb_idx][0] + \" \" + sentiment_word\n",
    "                else :\n",
    "                    break\n",
    "            list_sentiment_word.append(sentiment_word)\n",
    "            \n",
    "    return (list_sentiment_word, found_adjective)\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing(document) :\n",
    "    \n",
    "    act = ['acting',' role playing',' act',' actress',' actor',' role',' portray',' character',' villain',' performance', 'play', 'perform', 'doing']\n",
    "    plot = ['plot','story','storyline','tale','romance','dialog','script','storyteller',' ending','storytelling','revenge','betrayal','writing']\n",
    "    graphic = ['movie',' film',' picture',' moving picture','',' motion picture',' show',' picture show',' pic',' flick',' romantic comedy', 'graphic', 'effect']\n",
    "    \n",
    "    act_sentence = []\n",
    "    plot_sentence = []\n",
    "    graphic_sentence = []\n",
    "    \n",
    "    tokenizer = tokenize.PunktSentenceTokenizer()\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    list_sentence = tokenizer.sentences_from_text(document)\n",
    "    for sentence in list_sentence :\n",
    "        is_sentence_act = False\n",
    "        is_sentence_plot = False\n",
    "        is_sentence_graphic = False\n",
    "        list_word = tokenize.word_tokenize(sentence)\n",
    "        for word in list_word :\n",
    "            if (ps.stem(word.lower()) in act):\n",
    "#                 list_adj_sentence, adj_found = search_adj(sentence, word, True)\n",
    "                list_adj_sentence, adj_found = search_n_word(sentence, word, 5)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    act_sentence.append(word + \" is \" + adj_word)\n",
    "                    display(sentence, word + \" is \" + adj_word)\n",
    "            if (ps.stem(word.lower()) in plot):\n",
    "#                 list_adj_sentence, adj_found = search_adj(sentence, word, True)\n",
    "                list_adj_sentence, adj_found = search_n_word(sentence, word, 5)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    act_sentence.append(word + \" is \" + adj_word)\n",
    "                    display(sentence, word + \" is \" + adj_word)\n",
    "            if (ps.stem(word.lower()) in graphic):\n",
    "#                 list_adj_sentence, adj_found = search_adj(sentence, word, True)\n",
    "                list_adj_sentence, adj_found = search_n_word(sentence, word, 5)\n",
    "                for adj_word in (list_adj_sentence) :\n",
    "                    act_sentence.append(word + \" is \" + adj_word)\n",
    "                    display(sentence, word + \" is \" + adj_word)\n",
    "#             if (ps.stem(word.lower()) in act):\n",
    "#                 word_tag = st.tag([sentence])\n",
    "#                 for word_adj, tag in word_tag :\n",
    "#                     if (tag == 'JJ') :\n",
    "#                         act_sentence.append(word + \" is \" + word_adj)\n",
    "#                         display(sentence, word + \" is \" + word_adj)\n",
    "#             if (ps.stem(word.lower()) in plot):\n",
    "#                 word_tag = st.tag([sentence])\n",
    "#                 for word_adj, tag in word_tag :\n",
    "#                     if (tag == 'JJ') :\n",
    "#                         act_sentence.append(word + \" is \" + word_adj)\n",
    "#                         display(sentence, word + \" is \" + word_adj)\n",
    "#             if (ps.stem(word.lower()) in graphic):\n",
    "#                 word_tag = st.tag([sentence])\n",
    "#                 for word_adj, tag in word_tag :\n",
    "#                     if (tag == 'JJ') :\n",
    "#                         act_sentence.append(word + \" is \" + word_adj)\n",
    "#                         display(sentence, word + \" is \" + word_adj)\n",
    "    return ([act_sentence,plot_sentence, graphic_sentence])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../input/datasetnlp.xlsx\")\n",
    "data.drop(columns=['title'], inplace=True)\n",
    "for column_name in ['acting', 'plot', 'graphic'] :\n",
    "    data.loc[data[column_name] == 'positive', column_name] = 1\n",
    "    data.loc[data[column_name] == 'neutral', column_name] = 0\n",
    "    data.loc[data[column_name] == 'negative', column_name] = -1\n",
    "# display(data)\n",
    "\n",
    "tokenizer = tokenize.PunktSentenceTokenizer()\n",
    "# data.text = data.text.apply(lambda x: tokenizer.tokenize(x))\n",
    "data.text = data.text.apply(lambda x: preprocessing(x))\n",
    "\n",
    "\n",
    "# y = ps.stem(\"beating\")\n",
    "# display(y)\n",
    "display(data.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('script', 'NN'),\n",
       " ('does', 'VBZ'),\n",
       " ('manage', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('surprise', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('audience', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('end', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('plot', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('really', 'RB'),\n",
       " ('good', 'JJ')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['good']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "st = StanfordPOSTagger('./english-bidirectional-distsim.tagger', './stanford-postagger-3.9.2.jar') \n",
    "x = st.tag([\"the script does manage to surprise the audience at the end\", \"good plot is not really good\"])\n",
    "\n",
    "display(x, len(x))\n",
    "# import spacy\n",
    "# nlp = spacy.load('en')\n",
    "# doc = nlp(u'Mark and John are sincere employees at Google.')\n",
    "\n",
    "x = \"good plot\"\n",
    "a,b = search_adj(x, 'plot', False)\n",
    "display(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range (10,0,-1) :\n",
    "    display(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
